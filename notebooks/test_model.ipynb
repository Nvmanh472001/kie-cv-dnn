{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'model_type': 'det',\n 'algorithm': 'DB',\n 'Transform': None,\n 'Backbone': {'name': 'MobileNetV3',\n  'scale': 0.5,\n  'model_name': 'large',\n  'disable_se': True},\n 'Neck': {'name': 'RSEFPN', 'out_channels': 96, 'shortcut': True},\n 'Head': {'name': 'DBHead', 'k': 50}}"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import get_config_from_yaml\n",
    "\n",
    "det_yaml_path = '../configs/detection_config.yml'\n",
    "det_config = get_config_from_yaml(det_yaml_path)\n",
    "det_config['Architecture']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from modules.architectures import build_model\n",
    "\n",
    "det_model = build_model(det_config['Architecture'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "BaseModel(\n  (backbone): MobileNetV3(\n    (conv): ConvBNLayer(\n      (conv): Conv2d(3, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act): Activation(\n        (act): Hswish()\n      )\n    )\n    (stages): ModuleList(\n      (0): Sequential(\n        (0): ResidualUnit(\n          (expand_conv): ConvBNLayer(\n            (conv): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act): Activation(\n              (act): ReLU(inplace=True)\n            )\n          )\n          (bottleneck_conv): ConvBNLayer(\n            (conv): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n            (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act): Activation(\n              (act): ReLU(inplace=True)\n            )\n          )\n          (linear_conv): ConvBNLayer(\n            (conv): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (1): ResidualUnit(\n          (expand_conv): ConvBNLayer(\n            (conv): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act): Activation(\n              (act): ReLU(inplace=True)\n            )\n          )\n          (bottleneck_conv): ConvBNLayer(\n            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act): Activation(\n              (act): ReLU(inplace=True)\n            )\n          )\n          (linear_conv): ConvBNLayer(\n            (conv): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (2): ResidualUnit(\n          (expand_conv): ConvBNLayer(\n            (conv): Conv2d(16, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act): Activation(\n              (act): ReLU(inplace=True)\n            )\n          )\n          (bottleneck_conv): ConvBNLayer(\n            (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n            (bn): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act): Activation(\n              (act): ReLU(inplace=True)\n            )\n          )\n          (linear_conv): ConvBNLayer(\n            (conv): Conv2d(40, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (1): Sequential(\n        (0): ResidualUnit(\n          (expand_conv): ConvBNLayer(\n            (conv): Conv2d(16, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act): Activation(\n              (act): ReLU(inplace=True)\n            )\n          )\n          (bottleneck_conv): ConvBNLayer(\n            (conv): Conv2d(40, 40, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=40, bias=False)\n            (bn): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act): Activation(\n              (act): ReLU(inplace=True)\n            )\n          )\n          (linear_conv): ConvBNLayer(\n            (conv): Conv2d(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (1): ResidualUnit(\n          (expand_conv): ConvBNLayer(\n            (conv): Conv2d(24, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act): Activation(\n              (act): ReLU(inplace=True)\n            )\n          )\n          (bottleneck_conv): ConvBNLayer(\n            (conv): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64, bias=False)\n            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act): Activation(\n              (act): ReLU(inplace=True)\n            )\n          )\n          (linear_conv): ConvBNLayer(\n            (conv): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (2): ResidualUnit(\n          (expand_conv): ConvBNLayer(\n            (conv): Conv2d(24, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act): Activation(\n              (act): ReLU(inplace=True)\n            )\n          )\n          (bottleneck_conv): ConvBNLayer(\n            (conv): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64, bias=False)\n            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act): Activation(\n              (act): ReLU(inplace=True)\n            )\n          )\n          (linear_conv): ConvBNLayer(\n            (conv): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (2): Sequential(\n        (0): ResidualUnit(\n          (expand_conv): ConvBNLayer(\n            (conv): Conv2d(24, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act): Activation(\n              (act): Hswish()\n            )\n          )\n          (bottleneck_conv): ConvBNLayer(\n            (conv): Conv2d(120, 120, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=120, bias=False)\n            (bn): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act): Activation(\n              (act): Hswish()\n            )\n          )\n          (linear_conv): ConvBNLayer(\n            (conv): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (1): ResidualUnit(\n          (expand_conv): ConvBNLayer(\n            (conv): Conv2d(40, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act): Activation(\n              (act): Hswish()\n            )\n          )\n          (bottleneck_conv): ConvBNLayer(\n            (conv): Conv2d(104, 104, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=104, bias=False)\n            (bn): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act): Activation(\n              (act): Hswish()\n            )\n          )\n          (linear_conv): ConvBNLayer(\n            (conv): Conv2d(104, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (2): ResidualUnit(\n          (expand_conv): ConvBNLayer(\n            (conv): Conv2d(40, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act): Activation(\n              (act): Hswish()\n            )\n          )\n          (bottleneck_conv): ConvBNLayer(\n            (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n            (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act): Activation(\n              (act): Hswish()\n            )\n          )\n          (linear_conv): ConvBNLayer(\n            (conv): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (3): ResidualUnit(\n          (expand_conv): ConvBNLayer(\n            (conv): Conv2d(40, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act): Activation(\n              (act): Hswish()\n            )\n          )\n          (bottleneck_conv): ConvBNLayer(\n            (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n            (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act): Activation(\n              (act): Hswish()\n            )\n          )\n          (linear_conv): ConvBNLayer(\n            (conv): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (4): ResidualUnit(\n          (expand_conv): ConvBNLayer(\n            (conv): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act): Activation(\n              (act): Hswish()\n            )\n          )\n          (bottleneck_conv): ConvBNLayer(\n            (conv): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)\n            (bn): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act): Activation(\n              (act): Hswish()\n            )\n          )\n          (linear_conv): ConvBNLayer(\n            (conv): Conv2d(240, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (5): ResidualUnit(\n          (expand_conv): ConvBNLayer(\n            (conv): Conv2d(56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act): Activation(\n              (act): Hswish()\n            )\n          )\n          (bottleneck_conv): ConvBNLayer(\n            (conv): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n            (bn): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act): Activation(\n              (act): Hswish()\n            )\n          )\n          (linear_conv): ConvBNLayer(\n            (conv): Conv2d(336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (3): Sequential(\n        (0): ResidualUnit(\n          (expand_conv): ConvBNLayer(\n            (conv): Conv2d(56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act): Activation(\n              (act): Hswish()\n            )\n          )\n          (bottleneck_conv): ConvBNLayer(\n            (conv): Conv2d(336, 336, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=336, bias=False)\n            (bn): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act): Activation(\n              (act): Hswish()\n            )\n          )\n          (linear_conv): ConvBNLayer(\n            (conv): Conv2d(336, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (1): ResidualUnit(\n          (expand_conv): ConvBNLayer(\n            (conv): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act): Activation(\n              (act): Hswish()\n            )\n          )\n          (bottleneck_conv): ConvBNLayer(\n            (conv): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n            (bn): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act): Activation(\n              (act): Hswish()\n            )\n          )\n          (linear_conv): ConvBNLayer(\n            (conv): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (2): ResidualUnit(\n          (expand_conv): ConvBNLayer(\n            (conv): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act): Activation(\n              (act): Hswish()\n            )\n          )\n          (bottleneck_conv): ConvBNLayer(\n            (conv): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n            (bn): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act): Activation(\n              (act): Hswish()\n            )\n          )\n          (linear_conv): ConvBNLayer(\n            (conv): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (3): ConvBNLayer(\n          (conv): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act): Activation(\n            (act): Hswish()\n          )\n        )\n      )\n    )\n  )\n  (neck): RSEFPN(\n    (ins_conv): ModuleList(\n      (0): RSELayer(\n        (in_conv): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (se_block): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (conv1): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n          (relu1): Activation(\n            (act): ReLU(inplace=True)\n          )\n          (conv2): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))\n          (hard_sigmoid): Activation(\n            (act): Hsigmoid()\n          )\n        )\n      )\n      (1): RSELayer(\n        (in_conv): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (se_block): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (conv1): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n          (relu1): Activation(\n            (act): ReLU(inplace=True)\n          )\n          (conv2): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))\n          (hard_sigmoid): Activation(\n            (act): Hsigmoid()\n          )\n        )\n      )\n      (2): RSELayer(\n        (in_conv): Conv2d(56, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (se_block): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (conv1): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n          (relu1): Activation(\n            (act): ReLU(inplace=True)\n          )\n          (conv2): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))\n          (hard_sigmoid): Activation(\n            (act): Hsigmoid()\n          )\n        )\n      )\n      (3): RSELayer(\n        (in_conv): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (se_block): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (conv1): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n          (relu1): Activation(\n            (act): ReLU(inplace=True)\n          )\n          (conv2): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))\n          (hard_sigmoid): Activation(\n            (act): Hsigmoid()\n          )\n        )\n      )\n    )\n    (inp_conv): ModuleList(\n      (0): RSELayer(\n        (in_conv): Conv2d(96, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (se_block): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (conv1): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))\n          (relu1): Activation(\n            (act): ReLU(inplace=True)\n          )\n          (conv2): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))\n          (hard_sigmoid): Activation(\n            (act): Hsigmoid()\n          )\n        )\n      )\n      (1): RSELayer(\n        (in_conv): Conv2d(96, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (se_block): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (conv1): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))\n          (relu1): Activation(\n            (act): ReLU(inplace=True)\n          )\n          (conv2): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))\n          (hard_sigmoid): Activation(\n            (act): Hsigmoid()\n          )\n        )\n      )\n      (2): RSELayer(\n        (in_conv): Conv2d(96, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (se_block): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (conv1): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))\n          (relu1): Activation(\n            (act): ReLU(inplace=True)\n          )\n          (conv2): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))\n          (hard_sigmoid): Activation(\n            (act): Hsigmoid()\n          )\n        )\n      )\n      (3): RSELayer(\n        (in_conv): Conv2d(96, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (se_block): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (conv1): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))\n          (relu1): Activation(\n            (act): ReLU(inplace=True)\n          )\n          (conv2): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))\n          (hard_sigmoid): Activation(\n            (act): Hsigmoid()\n          )\n        )\n      )\n    )\n  )\n  (head): DBHead(\n    (binarize): Head(\n      (conv1): Conv2d(96, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (conv_bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu1): Activation(\n        (act): ReLU(inplace=True)\n      )\n      (conv2): ConvTranspose2d(24, 24, kernel_size=(2, 2), stride=(2, 2))\n      (conv_bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu2): Activation(\n        (act): ReLU(inplace=True)\n      )\n      (conv3): ConvTranspose2d(24, 1, kernel_size=(2, 2), stride=(2, 2))\n    )\n    (thresh): Head(\n      (conv1): Conv2d(96, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (conv_bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu1): Activation(\n        (act): ReLU(inplace=True)\n      )\n      (conv2): ConvTranspose2d(24, 24, kernel_size=(2, 2), stride=(2, 2))\n      (conv_bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu2): Activation(\n        (act): ReLU(inplace=True)\n      )\n      (conv3): ConvTranspose2d(24, 1, kernel_size=(2, 2), stride=(2, 2))\n    )\n  )\n)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "det_model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "{'model_type': 'rec',\n 'algorithm': 'SVTR',\n 'Transform': {'name': 'STN_ON',\n  'tps_inputsize': [32, 64],\n  'tps_outputsize': [48, 160],\n  'num_control_points': 20,\n  'tps_margins': [0.05, 0.05],\n  'stn_activation': 'none'},\n 'Backbone': {'name': 'SVTRNet',\n  'img_size': [48, 160],\n  'out_char_num': 40,\n  'out_channels': 256,\n  'patch_merging': 'Conv',\n  'embed_dim': [128, 256, 384],\n  'depth': [3, 6, 9],\n  'num_heads': [4, 8, 12],\n  'mixer': ['Local',\n   'Local',\n   'Local',\n   'Local',\n   'Local',\n   'Local',\n   'Local',\n   'Local',\n   'Global',\n   'Global',\n   'Global',\n   'Global',\n   'Global',\n   'Global',\n   'Global',\n   'Global',\n   'Global',\n   'Global'],\n  'local_mixer': [[7, 11], [7, 11], [7, 11]],\n  'last_stage': True,\n  'prenorm': False},\n 'Neck': {'name': 'SequenceEncoder', 'encoder_type': 'reshape'},\n 'Head': {'name': 'CTCHead'}}"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_yaml_path = \"../configs/recognition_config.yml\"\n",
    "rec_config = get_config_from_yaml(rec_yaml_path)\n",
    "rec_config['Architecture']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "rec_model = build_model(rec_config['Architecture'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "BaseModel(\n  (transform): STN_ON(\n    (tps): TPSSpatialTransformer()\n    (stn_head): STN(\n      (stn_convnet): Sequential(\n        (0): Sequential(\n          (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n        (2): Sequential(\n          (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n        (4): Sequential(\n          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n        (6): Sequential(\n          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n        (8): Sequential(\n          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n        (10): Sequential(\n          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n      )\n      (stn_fc1): Sequential(\n        (0): Linear(in_features=512, out_features=512, bias=True)\n        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n      )\n      (stn_fc2): Linear(in_features=512, out_features=40, bias=True)\n    )\n  )\n  (backbone): SVTRNet(\n    (patch_embed): PatchEmbed(\n      (proj): Sequential(\n        (0): ConvBNLayer(\n          (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act): Activation(\n            (act): GELU()\n          )\n        )\n        (1): ConvBNLayer(\n          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act): Activation(\n            (act): GELU()\n          )\n        )\n      )\n    )\n    (pos_drop): Dropout(p=0.0, inplace=False)\n    (blocks1): ModuleList(\n      (0): Block(\n        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n        (mixer): Attention(\n          (qkv): Linear(in_features=128, out_features=384, bias=True)\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=128, out_features=128, bias=True)\n          (proj_drop): Dropout(p=0.0, inplace=False)\n        )\n        (drop_path): Identity()\n        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=128, out_features=512, bias=True)\n          (act): Activation(\n            (act): GELU()\n          )\n          (fc2): Linear(in_features=512, out_features=128, bias=True)\n          (drop): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (1): Block(\n        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n        (mixer): Attention(\n          (qkv): Linear(in_features=128, out_features=384, bias=True)\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=128, out_features=128, bias=True)\n          (proj_drop): Dropout(p=0.0, inplace=False)\n        )\n        (drop_path): DropPath()\n        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=128, out_features=512, bias=True)\n          (act): Activation(\n            (act): GELU()\n          )\n          (fc2): Linear(in_features=512, out_features=128, bias=True)\n          (drop): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (2): Block(\n        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n        (mixer): Attention(\n          (qkv): Linear(in_features=128, out_features=384, bias=True)\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=128, out_features=128, bias=True)\n          (proj_drop): Dropout(p=0.0, inplace=False)\n        )\n        (drop_path): DropPath()\n        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=128, out_features=512, bias=True)\n          (act): Activation(\n            (act): GELU()\n          )\n          (fc2): Linear(in_features=512, out_features=128, bias=True)\n          (drop): Dropout(p=0.0, inplace=False)\n        )\n      )\n    )\n    (sub_sample1): SubSample(\n      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 1), padding=(1, 1))\n      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n    )\n    (blocks2): ModuleList(\n      (0): Block(\n        (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n        (mixer): Attention(\n          (qkv): Linear(in_features=256, out_features=768, bias=True)\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=256, out_features=256, bias=True)\n          (proj_drop): Dropout(p=0.0, inplace=False)\n        )\n        (drop_path): DropPath()\n        (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=256, out_features=1024, bias=True)\n          (act): Activation(\n            (act): GELU()\n          )\n          (fc2): Linear(in_features=1024, out_features=256, bias=True)\n          (drop): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (1): Block(\n        (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n        (mixer): Attention(\n          (qkv): Linear(in_features=256, out_features=768, bias=True)\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=256, out_features=256, bias=True)\n          (proj_drop): Dropout(p=0.0, inplace=False)\n        )\n        (drop_path): DropPath()\n        (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=256, out_features=1024, bias=True)\n          (act): Activation(\n            (act): GELU()\n          )\n          (fc2): Linear(in_features=1024, out_features=256, bias=True)\n          (drop): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (2): Block(\n        (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n        (mixer): Attention(\n          (qkv): Linear(in_features=256, out_features=768, bias=True)\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=256, out_features=256, bias=True)\n          (proj_drop): Dropout(p=0.0, inplace=False)\n        )\n        (drop_path): DropPath()\n        (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=256, out_features=1024, bias=True)\n          (act): Activation(\n            (act): GELU()\n          )\n          (fc2): Linear(in_features=1024, out_features=256, bias=True)\n          (drop): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (3): Block(\n        (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n        (mixer): Attention(\n          (qkv): Linear(in_features=256, out_features=768, bias=True)\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=256, out_features=256, bias=True)\n          (proj_drop): Dropout(p=0.0, inplace=False)\n        )\n        (drop_path): DropPath()\n        (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=256, out_features=1024, bias=True)\n          (act): Activation(\n            (act): GELU()\n          )\n          (fc2): Linear(in_features=1024, out_features=256, bias=True)\n          (drop): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (4): Block(\n        (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n        (mixer): Attention(\n          (qkv): Linear(in_features=256, out_features=768, bias=True)\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=256, out_features=256, bias=True)\n          (proj_drop): Dropout(p=0.0, inplace=False)\n        )\n        (drop_path): DropPath()\n        (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=256, out_features=1024, bias=True)\n          (act): Activation(\n            (act): GELU()\n          )\n          (fc2): Linear(in_features=1024, out_features=256, bias=True)\n          (drop): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (5): Block(\n        (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n        (mixer): Attention(\n          (qkv): Linear(in_features=256, out_features=768, bias=True)\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=256, out_features=256, bias=True)\n          (proj_drop): Dropout(p=0.0, inplace=False)\n        )\n        (drop_path): DropPath()\n        (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=256, out_features=1024, bias=True)\n          (act): Activation(\n            (act): GELU()\n          )\n          (fc2): Linear(in_features=1024, out_features=256, bias=True)\n          (drop): Dropout(p=0.0, inplace=False)\n        )\n      )\n    )\n    (sub_sample2): SubSample(\n      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 1), padding=(1, 1))\n      (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n    )\n    (blocks3): ModuleList(\n      (0): Block(\n        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n        (mixer): Attention(\n          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=384, out_features=384, bias=True)\n          (proj_drop): Dropout(p=0.0, inplace=False)\n        )\n        (drop_path): DropPath()\n        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n          (act): Activation(\n            (act): GELU()\n          )\n          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n          (drop): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (1): Block(\n        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n        (mixer): Attention(\n          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=384, out_features=384, bias=True)\n          (proj_drop): Dropout(p=0.0, inplace=False)\n        )\n        (drop_path): DropPath()\n        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n          (act): Activation(\n            (act): GELU()\n          )\n          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n          (drop): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (2): Block(\n        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n        (mixer): Attention(\n          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=384, out_features=384, bias=True)\n          (proj_drop): Dropout(p=0.0, inplace=False)\n        )\n        (drop_path): DropPath()\n        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n          (act): Activation(\n            (act): GELU()\n          )\n          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n          (drop): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (3): Block(\n        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n        (mixer): Attention(\n          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=384, out_features=384, bias=True)\n          (proj_drop): Dropout(p=0.0, inplace=False)\n        )\n        (drop_path): DropPath()\n        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n          (act): Activation(\n            (act): GELU()\n          )\n          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n          (drop): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (4): Block(\n        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n        (mixer): Attention(\n          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=384, out_features=384, bias=True)\n          (proj_drop): Dropout(p=0.0, inplace=False)\n        )\n        (drop_path): DropPath()\n        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n          (act): Activation(\n            (act): GELU()\n          )\n          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n          (drop): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (5): Block(\n        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n        (mixer): Attention(\n          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=384, out_features=384, bias=True)\n          (proj_drop): Dropout(p=0.0, inplace=False)\n        )\n        (drop_path): DropPath()\n        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n          (act): Activation(\n            (act): GELU()\n          )\n          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n          (drop): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (6): Block(\n        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n        (mixer): Attention(\n          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=384, out_features=384, bias=True)\n          (proj_drop): Dropout(p=0.0, inplace=False)\n        )\n        (drop_path): DropPath()\n        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n          (act): Activation(\n            (act): GELU()\n          )\n          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n          (drop): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (7): Block(\n        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n        (mixer): Attention(\n          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=384, out_features=384, bias=True)\n          (proj_drop): Dropout(p=0.0, inplace=False)\n        )\n        (drop_path): DropPath()\n        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n          (act): Activation(\n            (act): GELU()\n          )\n          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n          (drop): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (8): Block(\n        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n        (mixer): Attention(\n          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=384, out_features=384, bias=True)\n          (proj_drop): Dropout(p=0.0, inplace=False)\n        )\n        (drop_path): DropPath()\n        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n          (act): Activation(\n            (act): GELU()\n          )\n          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n          (drop): Dropout(p=0.0, inplace=False)\n        )\n      )\n    )\n    (avg_pool): AdaptiveAvgPool2d(output_size=[1, 40])\n    (last_conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (hardswish): Activation(\n      (act): Hswish()\n    )\n    (dropout): Dropout(p=0.0, inplace=False)\n    (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n  )\n  (neck): SequenceEncoder(\n    (encoder_reshape): Im2Seq()\n  )\n  (head): CTCHead(\n    (fc): Linear(in_features=256, out_features=6625, bias=True)\n  )\n)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_model.eval()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
